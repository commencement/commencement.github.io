<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=7.0000" http-equiv="X-UA-Compatible">
  <title>Zili Wang's Homepage</title>
  <meta name="description" content="Zili Wang, Algorithm Engineer at Xiaohongshu Inc.">
  <meta name="keywords" content="Zili Wang, Large Language Model Pre-training">
  <link rel="stylesheet" type="text/css" href="./files/ZiliWang.css">

  <style>
    @-moz-keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    @-webkit-keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    @-o-keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    @keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    embed,
    object {
      animation-duration: .001s;
      -ms-animation-duration: .001s;
      -moz-animation-duration: .001s;
      -webkit-animation-duration: .001s;
      -o-animation-duration: .001s;
      animation-name: nodeInserted;
      -ms-animation-name: nodeInserted;
      -moz-animation-name: nodeInserted;
      -webkit-animation-name: nodeInserted;
      -o-animation-name: nodeInserted;
    }

    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      font-size: 18px;
      line-height: 1.6;
      margin: 0;
      background-color: #f8f9fa;
      min-height: 100vh;
    }

    #content {
      max-width: 1000px;
      margin: 0 auto;
      background-color: white;
      padding: 40px;
      border-radius: 10px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      margin-top: 20px;
      margin-bottom: 20px;
    }

    .header-section {
      text-align: center;
      margin-bottom: 40px;
      padding-bottom: 30px;
      border-bottom: 3px solid #667eea;
    }

    .profile-image {
      border-radius: 50%;
      border: 4px solid #667eea;
      box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    .name-title {
      font-size: 2.5em;
      font-weight: 700;
      color: #2c3e50;
      margin: 20px 0 10px 0;
      text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }

    .bio {
      font-size: 1.1em;
      line-height: 1.8;
      color: #555;
      max-width: 800px;
      margin: 0 auto;
      text-align: justify;
    }

    h2 {
      color: #2c3e50;
      border-bottom: 2px solid #dee2e6;
      padding-bottom: 10px;
      margin-top: 40px;
      margin-bottom: 25px;
      font-size: 1.8em;
      font-weight: 600;
      text-align: center;
    }

    .highlight {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 15px;
      border-radius: 10px;
      font-weight: bold;
      display: inline-block;
      margin: 20px 0;
      text-align: center;
      box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    .model-info {
      margin-bottom: 25px;
      padding: 20px;
      border-left: 4px solid #007bff;
      background-color: #f8f9fa;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      font-size: 18px;
    }

    .model-info:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 15px rgba(0,0,0,0.15);
    }

    .model-info p {
      margin: 8px 0;
      line-height: 1.7;
      color: #444;
    }

    .model-info strong {
      color: #2c3e50;
      font-size: 1.1em;
    }

    .model-info a {
      color: #007bff;
      font-weight: bold;
      transition: color 0.3s ease;
    }

    .model-info a:hover {
      color: #0056b3;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 25px;
      background: white;
      border-radius: 10px;
      overflow: hidden;
      box-shadow: 0 3px 10px rgba(0,0,0,0.1);
    }

    td {
      padding: 15px;
      border-bottom: 1px solid #eee;
      transition: background-color 0.3s ease;
    }

    tr:hover td {
      background-color: #f8f9fa;
    }

    .left {
      width: 80px;
      text-align: center;
      vertical-align: top;
      padding-top: 15px;
    }

    .title {
      font-weight: bold;
      color: #2c3e50;
      font-size: 1.05em;
    }

    a {
      color: #007bff;
      text-decoration: none;
      font-weight: 500;
      transition: color 0.3s ease;
    }

    a:hover {
      color: #0056b3;
      text-decoration: underline;
    }

    .professional-services-list {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 15px;
      margin: 20px 0;
    }

    .service-item {
      background-color: #f8f9fa;
      padding: 15px;
      border-radius: 8px;
      border-left: 3px solid #007bff;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }

    .service-item:hover {
      transform: translateY(-1px);
      box-shadow: 0 3px 10px rgba(0,0,0,0.1);
    }

    .service-type {
      font-weight: 600;
      color: #495057;
      display: block;
      margin-bottom: 5px;
    }

    .conference-link {
      color: #007bff;
      text-decoration: none;
      font-weight: 500;
      transition: color 0.2s ease;
    }

    .conference-link:hover {
      color: #0056b3;
      text-decoration: underline;
    }

    .stats-container {
      text-align: center;
      margin: 30px 0;
      padding: 20px;
      background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
      border-radius: 15px;
      border: 2px solid #667eea;
    }

    .stats-number {
      font-size: 2em;
      font-weight: bold;
      color: #667eea;
      margin: 10px 0;
    }

    .stats-label {
      color: #666;
      font-size: 1.1em;
    }

    td {
      padding: 10px; /* Add padding for better readability */
    }

    .title {
      font-size: 15px; /* Larger font size for titles */
      font-weight: bold; /* Make titles bold */
    }

    p {
      margin: 10px 0; /* Add margin for spacing between paragraphs */
    }

    a {
      font-weight: bold; /* Make links bold */
      text-decoration: none; /* Remove underlines for a cleaner look */
    }
  </style>

<script>
// 缓存GitHub仓库的星标数
const githubStarsCache = {};

// 获取GitHub仓库的星标数（使用公共API，无需token）
async function fetchGitHubStars(repo, elementId) {
    try {
        if (githubStarsCache[repo]) {
            document.getElementById(elementId).textContent = `⭐ ${githubStarsCache[repo]}`;
            return;
        }
        
        // 使用公共API，添加随机延迟避免限流
        await new Promise(resolve => setTimeout(resolve, Math.random() * 2000 + 1000));
        
        const response = await fetch(`https://api.github.com/repos/${repo}`, {
            headers: {
                'Accept': 'application/vnd.github.v3+json',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
        });
        
        if (!response.ok) {
            if (response.status === 403) {
                // 如果遇到限流，显示默认值
                document.getElementById(elementId).textContent = '⭐ ~';
                return;
            }
            throw new Error(`HTTP error! Status: ${response.status}`);
        }
        
        const data = await response.json();
        const stars = data.stargazers_count;
        githubStarsCache[repo] = stars;
        document.getElementById(elementId).textContent = `⭐ ${stars}`;
    } catch (error) {
        console.error(`Error fetching GitHub stars for ${repo}:`, error);
        // 显示默认值而不是Error
        document.getElementById(elementId).textContent = '⭐ ~';
    }
}

// 获取Hugging Face模型的下载次数
async function fetchHuggingFaceDownloads(model, elementId) {
    try {
        console.log(`Fetching downloads for ${model}...`);
        
        // 添加延迟避免限流
        await new Promise(resolve => setTimeout(resolve, Math.random() * 1000 + 500));
        
        const response = await fetch(`https://huggingface.co/api/models/${model}`, {
            headers: {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
        });
        
        if (!response.ok) {
            if (response.status === 429) {
                console.log(`Rate limited for ${model}`);
                document.getElementById(elementId).textContent = '⬇️ ~';
                return;
            }
            throw new Error(`HTTP error! Status: ${response.status}`);
        }
        
        const data = await response.json();
        const downloads = data.downloads || 0;
        console.log(`${model}: ${downloads} downloads`);
        document.getElementById(elementId).textContent = `⬇️ ${downloads.toLocaleString()}`;
    } catch (error) {
        console.error(`Error fetching Hugging Face downloads for ${model}:`, error);
        document.getElementById(elementId).textContent = '⬇️ ~';
    }
}

// 计算OpenCoder所有模型的下载数总和
async function fetchOpenCoderTotalDownloads() {
    try {
        console.log('Fetching OpenCoder total downloads...');
        
        const openCoderModels = [
            'infly/OpenCoder-1.5B-Base',
            'infly/OpenCoder-8B-Base', 
            'infly/OpenCoder-1.5B-Instruct',
            'infly/OpenCoder-8B-Instruct'
        ];
        
        let totalDownloads = 0;
        
        for (let i = 0; i < openCoderModels.length; i++) {
            const model = openCoderModels[i];
            try {
                // 添加延迟避免限流
                await new Promise(resolve => setTimeout(resolve, Math.random() * 1000 + 500));
                
                const response = await fetch(`https://huggingface.co/api/models/${model}`, {
                    headers: {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                    }
                });
                
                if (response.ok) {
                    const data = await response.json();
                    const downloads = data.downloads || 0;
                    totalDownloads += downloads;
                    console.log(`${model}: ${downloads} downloads`);
                }
            } catch (error) {
                console.error(`Error fetching downloads for ${model}:`, error);
            }
        }
        
        console.log(`OpenCoder total downloads: ${totalDownloads}`);
        document.getElementById('opencoder-downloads').textContent = `⬇️ ${totalDownloads.toLocaleString()}`;
    } catch (error) {
        console.error('Error fetching OpenCoder total downloads:', error);
        document.getElementById('opencoder-downloads').textContent = '⬇️ ~';
    }
}

// 批量获取GitHub仓库的星标数（添加延迟避免限流）
async function fetchMultipleGitHubStars(repos) {
    for (let i = 0; i < repos.length; i++) {
        const { repo, elementId } = repos[i];
        await fetchGitHubStars(repo, elementId);
        // 添加延迟避免GitHub API限流
        if (i < repos.length - 1) {
            await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));
        }
    }
}

// 在页面加载时调用函数
document.addEventListener('DOMContentLoaded', () => {
    fetchHuggingFaceDownloads('infly/INF-34B-Base', 'inf-34b-downloads');
    // 计算OpenCoder所有模型的下载数总和
    fetchOpenCoderTotalDownloads();

    
    const githubRepos = [
        { repo: 'stepfun-ai/Step3', elementId: 'step3-stars' },
        { repo: 'infly-ai/INF-LLM', elementId: 'inf-llm-stars' },
        { repo: 'infly-ai/INF-LLM', elementId: 'inf-llm-2-stars' },
        { repo: 'opencoder-llm/opencoder-llm', elementId: 'opencoder-stars' },
        { repo: 'Bumble666/Hyper_MoE', elementId: 'hyper-moe-stars' },
        { repo: 'mutonix/RefGPT', elementId: 'ref-gpt-stars' },
        { repo: 'MikeGu721/XiezhiBenchmark', elementId: 'xiezhi-benchmark-stars' },
        { repo: 'WaitHZ/GW-MoE', elementId: 'gw-moe-stars' },
        { repo: 'kamanphoebe/Look-into-MoEs', elementId: 'look-into-moes-stars' },

        { repo: 'sanderwood/bgpt', elementId: 'bgpt-stars' },
        { repo: 'geekan/MetaGPT', elementId: 'metagpt-stars' },
        { repo: 'RuifengYuan/Evolving-LLM-Assistant', elementId: 'evolving-llm-stars' }

    ];
    
    fetchMultipleGitHubStars(githubRepos);
});

</script>



</head>

<body>
  <div id="content">
    <div id="left">
      <table style="background-color:white;">
        <tbody>
          <tr nosave="">
            <td valign="CENTER">
              <img src="./images/ziliwang_new.jpg" height="250" align="left">
            </td>

            <td valign="CENTER" width="2%">
            </td>

            <td valign="CENTER" halign="LEFT">
              <font size="+0">
                <b><font size="+2">Zili Wang&nbsp;</font></b>
                <p style="margin-left:0px;">
                  <img src="./images/ziliwang_name.png" height="60">
                </p>
                <p style="margin-left:0px;">
                  <!-- <b>Algorithm Expert</b> -->
                </p>
                <p style="margin-left:0px;">
                  <!-- <a href="http://www.nextcenter.org/", target="_blank">NExT++</a><br/> -->
                  <a href="https://stepfun.com/" target="_blank">StepFun</a><br/>
                  <!-- <a href="https://www.polyu.edu.hk/", target="_blank">Hong Kong Polytechnic University</a><br/> -->
                </p>
                <p style="margin-left:0px;">
                  Shang Hai, China<br>
                </p>
                <p style="margin-left:0px;">
                  Email: ziliwang.do@gmail.com<br>
                  &bull; <a href="">CV</a> &bull; <a href="https://scholar.google.com/citations?hl=zh-CN&user=E9zWgmwAAAAJ">Google Scholar</a> &bull; <a href="https://github.com/commencement">GitHub</a> <br>
                </p>
              </font>
              <p><font size="+0">
                </font>
              </p>
            </td>
          </tr>
        </tbody>
      </table>

      <div style="margin-top:20px;">
        Zili Wang is currently an LLM Researcher at <a href="https://stepfun.com/">StepFun</a> (October 2024 - Present), focusing on large language model pretraining, particularly leading the Step3 project, supervised by <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&hl=zh-CN">Prof. Yu Bai</a>. Previously, he worked as an Algorithm Expert at <a href="https://www.infly.cn/">INF Technology</a> (September 2023 - September 2024), an Algorithm Engineer at Xiaohongshu Inc. (March 2022 - September 2023) with <a href="https://wangshusen.github.io/">Prof. Shusen Wang</a>, and a Research Assistant at Hong Kong Polytechnic University (February 2020 - March 2022) with <a href="https://www4.comp.polyu.edu.hk/~cswjli/">Prof. Wenjie Li</a>.
      </div>

      <h2 style="CLEAR: both;">Recent Projects</h2>

      <div class="model-info">
        <p><strong>OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models</strong></p>
        <p>OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B base and chat models, supporting both English and Chinese languages. Starting from scratch, OpenCoder is trained on 2.5 trillion tokens composed of 90% raw code and 10% code-related web data, reaching the performance of top-tier code LLMs. We provide not only model weights and inference code, but also the reproducible training data, the complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols.</p>
        <p>Links:
          <a href="https://github.com/opencoder-llm/opencoder-llm" target="_blank">
            <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" style="width: 16px; height: 16px; vertical-align: middle;"> GitHub
          </a> 
          <span id="opencoder-stars"></span>
          |
          <a href="https://huggingface.co/opencoder-llm" target="_blank">
            <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="HuggingFace" style="width: 16px; height: 16px; vertical-align: middle;"> HuggingFace
          </a> 
          <span id="opencoder-downloads"></span>
          |
          <a href="https://opencoder-llm.github.io/" target="_blank">
            <img src="https://cdn-icons-png.flaticon.com/512/1006/1006771.png" alt="Project Page" style="width: 16px; height: 16px; vertical-align: middle;"> Project Page
          </a>
          |
          <a href="https://arxiv.org/pdf/2411.04905" target="_blank">
            <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" alt="Paper" style="width: 16px; height: 16px; vertical-align: middle;"> Paper
          </a>
        </p>
      </div>

      <div class="model-info">
        <p><strong>Step3: Cost-Effective Multimodal Intelligence</strong></p>
        <p>Step3 is our cutting-edge multimodal reasoning model—built on a massive Mixture-of-Experts architecture with 321 billion total parameters and 38 billion active. It is designed end-to-end to minimize decoding costs while delivering top-tier performance in vision–language reasoning, mathematics, and code. Through the co-design of Multi-Matrix Factorization Attention (MFA) and Attention-FFN Disaggregation (AFD), Step3 maintains exceptional efficiency across both flagship and low-end accelerators.</p>
        <p>Links:
          <a href="https://github.com/stepfun-ai/Step3" target="_blank">
            <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" style="width: 16px; height: 16px; vertical-align: middle;"> GitHub
          </a> 
          <span id="step3-stars"></span>
          |
          <a href="https://stepfun.com/" target="_blank">
            <img src="https://cdn-icons-png.flaticon.com/512/1006/1006771.png" alt="Project Page" style="width: 16px; height: 16px; vertical-align: middle;"> Project Page
          </a>
          |
          <a href="https://arxiv.org/abs/2507.19427" target="_blank">
            <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" alt="Paper" style="width: 16px; height: 16px; vertical-align: middle;"> Paper
          </a>
        </p>
      </div>


      <div class="model-info">
        <p><strong>INF-34B: INF’s Open-Source Large Language Models</strong></p>
        <p>INF-34B has 34 billion parameters with a context window length of 32K, and is trained on about 3.5T well-processed tokens from English and Chinese bilingual corpus. Compared with open source models of comparable size, INF-34B not only provides competitive performance in the OpenCompass evaluation, but also has impressive potential in both finance and healthcare domains. Besides, the quantized INF-34B runs on graphics cards of 24GB VRAM with negligible accuracy loss, which facilitates commercial applications, especially low-resource scenarios.</p>
        <p>Links:
          <a href="https://github.com/infly-ai/INF-LLM" target="_blank">
            <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" style="width: 16px; height: 16px; vertical-align: middle;"> GitHub
          </a> 
          <span id="inf-llm-stars"></span>
          |
          <a href="https://huggingface.co/infly/INF-34B-Base" target="_blank">
            <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="HuggingFace" style="width: 16px; height: 16px; vertical-align: middle;"> HuggingFace
          </a> 
          <span id="inf-34b-downloads"></span>
          |
          <a href="https://s.infly.cn/f/img/pdf/inf_34b_tech_report.pdf" target="_blank">
            <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" alt="Tech Report" style="width: 16px; height: 16px; vertical-align: middle;"> Tech Report
          </a>
        </p>
      </div>



      <h2 style="CLEAR: both">Selected Publications</h2>
      </br>

      <table>
        <tbody>
               <tr>
                <td class="left">
                    <a href="https://arxiv.org/abs/2405.19327" target="_blank">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" width="25" height="25"><br>arXiv
                    </a>
                </td>
                <td>
                    <span class="title">INF’s Open-Source Large Language Models</span>
                    <br>Jiaran Hao, <b>Zili Wang</b>, LiuYihan Song, Ansheng You, Zhipeng Zhou, Xiaoyu Tan, Dakuan Lu, Xiaoming Shi, Chao Qu, Haozhe Wang, Yinghui Xu, Wei Chu, Yuan Qi
                    <!-- <br>&nbsp;&nbsp;&bull; <a href="https://s.infly.cn/f/img/pdf/inf_34b_tech_report.pdf" target="_blank">arXiv</a> &nbsp;&nbsp; -->
                    <br>&bull; <a href="https://github.com/infly-ai/INF-LLM/" target="_blank">Github</a> <span id="inf-llm-2-stars"></span> &nbsp;&nbsp;
                    &bull; <a href="https://huggingface.co/infly/INF-34B-Base/" target="_blank">Huggingface</a> &nbsp;&nbsp;
                </td>
            </tr>




            <tr>
                <td class="left">
                    <a href="https://arxiv.org/pdf/2402.12656" target="_blank">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" width="25" height="25"><br>arXiv
                    </a>
                </td>
                <td>
                    <span class="title">HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts</span>
                    <br>Hao Zhao, Zihan Qiu, Huijia Wu, <b>Zili Wang</b>, Zhaofeng He, Jie Fu
                    <br>ACL 2024
                    <!-- <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/pdf/2402.12656" target="_blank">arXiv</a> &nbsp;&nbsp; -->
                    <br>&bull; <a href="https://github.com/Bumble666/Hyper_MoE" target="_blank">Github</a> <span id="hyper-moe-stars"></span> &nbsp;&nbsp;
                </td>
            </tr>

            <tr>
                <td class="left">
                    <a href="https://arxiv.org/pdf/2305.14994.pdf" target="_blank">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" width="25" height="25"><br>arXiv
                    </a>
                </td>
                <td>
                    <span class="title">RefGPT: Reference-> Truthful & Customized Dialogues Generation by GPTs and for GPTs</span>
                    <br>Dongjie Yang, Ruifeng Yuan, YuanTao Fan, YiFei Yang, <b>Zili Wang</b>, Shushen Wang, Hai Zhao
                    <br>EMNLP 2023
                    <!-- <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2305.14994" target="_blank">arXiv</a> &nbsp;&nbsp; -->
                    <br>&bull; <a href="https://github.com/mutonix/RefGPT" target="_blank">Github</a> <span id="ref-gpt-stars"></span> &nbsp;&nbsp;
                </td>
            </tr>

            <tr>
                <td class="left">
                    <a href="https://arxiv.org/pdf/2306.05783.pdf" target="_blank">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" width="25" height="25"><br>arXiv
                    </a>
                </td>
                <td>
                    <span class="title">Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation</span>
                    <br>Zhouhong Gu, Xiaoxuan Zhu, Haoning Ye, Lin Zhang, Jianchen Wang, Sihang Jiang, Zhuozhi Xiong, Zihan Li, Qianyu He, Rui Xu, Wenhao Huang, <b>Zili Wang</b>, Shusen Wang, Weiguo Zheng, Hongwei Feng, Yanghua Xiao
                    <br>AAAI 2024
                    <!-- <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2306.05783" target="_blank">arXiv</a> &nbsp;&nbsp; -->
                    <br>&bull; <a href="https://github.com/MikeGu721/XiezhiBenchmark" target="_blank">Github</a> <span id="xiezhi-benchmark-stars"></span> &nbsp;&nbsp;
                </td>
            </tr>

            <tr>
                <td class="left">
                    <a href="https://arxiv.org/abs/2406.12375" target="_blank">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" width="25" height="25"><br>arXiv
                    </a>
                </td>
                <td>
                    <span class="title">GW-MoE: Resolving Uncertainty in MoE Router with Global Workspace Theory</span>
                    <br>Haoze Wu, Zihan Qiu, <b>Zili Wang</b>, Hang Zhao, Jie Fu
                    <!-- <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2406.12375" target="_blank">arXiv</a> &nbsp;&nbsp; -->
                    <br>&bull; <a href="https://github.com/WaitHZ/GW-MoE" target="_blank">Github</a> <span id="gw-moe-stars"></span> &nbsp;&nbsp;
                </td>
            </tr>

            <tr>
                <td class="left">
                    <a href="https://arxiv.org/pdf/2406.18219" target="_blank">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" width="25" height="25"><br>arXiv
                    </a>
                </td>
                <td>
                    <span class="title">A Closer Look into Mixture-of-Experts in Large Language Models</span>
                    <br>Ka Man Lo, Zeyu Huang, Zihan Qiu, <b>Zili Wang</b>, Jie Fu
                    <!-- <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2406.18219" target="_blank">arXiv</a> &nbsp;&nbsp; -->
                    <br>&bull; <a href="https://github.com/kamanphoebe/Look-into-MoEs" target="_blank">Github</a> <span id="look-into-moes-stars"></span> &nbsp;&nbsp;

                </td>
            </tr>

            <tr>
                <td class="left">
                    <a href="https://arxiv.org/pdf/2312.17257" target="_blank">
                        <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" width="25" height="25"><br>arXiv
                    </a>
                </td>
                <td>
                    <span class="title">Evolving Large Language Model Assistant with Long-Term Conditional Memory</span>
                    <br>Ruifeng Yuan, Shichao Sun, <b>Zili Wang</b>, Ziqiang Cao, Wenjie Li
                    <!-- <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/pdf/2312.17257" target="_blank">arXiv</a> &nbsp;&nbsp; -->
                    <br>&bull; <a href="https://github.com/RuifengYuan/Evolving-LLM-Assistant" target="_blank">Github</a> <span id="evolving-llm-stars"></span> &nbsp;&nbsp;
                </td>
            </tr>


        </tbody>
      </table>






      <h2 style="CLEAR: both;">Professional Services</h2>
      <div class="professional-services-list">
        <div class="service-item">
          <span class="service-type">Program Committee Member</span>
          <a href="https://aaai.org/aaai-conference/" target="_blank" class="conference-link">AAAI 2026</a>
        </div>
        <div class="service-item">
          <span class="service-type">Program Committee Member</span>
          <a href="https://www.cikm2025.org/" target="_blank" class="conference-link">ACM CIKM 2025</a>
        </div>
        <div class="service-item">
          <span class="service-type">Program Committee Member</span>
          <a href="https://www.cikm2023.org/" target="_blank" class="conference-link">ACM CIKM 2023</a>
        </div>
        <div class="service-item">
          <span class="service-type">Program Committee Member</span>
          <a href="https://www.cikm2022.org/" target="_blank" class="conference-link">ACM CIKM 2022</a>
        </div>
        <div class="service-item">
          <span class="service-type">Program Committee Member</span>
          <a href="https://www.cikm2021.org/" target="_blank" class="conference-link">ACM CIKM 2021</a>
        </div>
        <div class="service-item">
          <span class="service-type">Reviewer</span>
          <a href="https://2024.aclweb.org/" target="_blank" class="conference-link">ACL 2025, 2024</a>
        </div>
        <div class="service-item">
          <span class="service-type">Reviewer</span>
          <a href="https://neurips.cc/" target="_blank" class="conference-link">NeurIPS</a>
        </div>
      </div>
      </td></tr></tbody></table>

      </br>

      <div class="stats-container">
        <div class="stats-number">37,586</div>
        <div class="stats-label">Total Page Views</div>
        <p style="margin-top: 15px; color: #888; font-size: 0.9em;">Thank you for visiting my homepage!</p>
      </div>
    </div>
  </div>
</body>
</html>
