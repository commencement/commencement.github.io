<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=7.0000" http-equiv="X-UA-Compatible">
  <title>Zili Wang's Homepage</title>
  <meta name="description" content="Zili Wang, Algorithm Engineer at Xiaohongshu Inc.">
  <meta name="keywords" content="Zili Wang, Large Language Model Pre-training">
  <link rel="stylesheet" type="text/css" href="./files/ZiliWang.css">

  <style>
    @-moz-keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    @-webkit-keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    @-o-keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    @keyframes nodeInserted {
      from {
        opacity: 0.99;
      }
      to {
        opacity: 1;
      }
    }
    embed,
    object {
      animation-duration: .001s;
      -ms-animation-duration: .001s;
      -moz-animation-duration: .001s;
      -webkit-animation-duration: .001s;
      -o-animation-duration: .001s;
      animation-name: nodeInserted;
      -ms-animation-name: nodeInserted;
      -moz-animation-name: nodeInserted;
      -webkit-animation-name: nodeInserted;
      -o-animation-name: nodeInserted;
    }

    body {
      font-size: 18px; /* Increase base font size */
      line-height: 1.6;
      margin: 0; /* Remove default margin */
    }

    #content {
      max-width: 2000px; /* Set max width for content */
      margin: 0 auto; /* Center content */
      padding: 20px; /* Add padding for spacing */
    }

    h2 {
      font-size: 24px;
      font-weight: bold;
    }

    .highlight {
      background-color: #ffeb3b;
      padding: 10px;
      border-radius: 5px;
      font-weight: bold;
      display: inline-block;
      margin: 20px 0;
    }

    .model-info {
      background-color: #e0f7fa;
      padding: 15px;
      border-radius: 5px;
      margin: 20px 0;
      font-size: 18px; /* Increase font size */
    }

    .model-info a {
      color: #00796b;
      font-weight: bold;
    }

    table {
      width: 100%; /* Ensure tables take full width */
    }

    td {
      padding: 10px; /* Add padding for better readability */
    }

    .title {
      font-size: 15px; /* Larger font size for titles */
      font-weight: bold; /* Make titles bold */
    }

    p {
      margin: 10px 0; /* Add margin for spacing between paragraphs */
    }

    a {
      font-weight: bold; /* Make links bold */
      text-decoration: none; /* Remove underlines for a cleaner look */
    }
  </style>
</head>

<body>
  <div id="content">
    <div id="left">
      <table style="background-color:white;">
        <tbody>
          <tr nosave="">
            <td valign="CENTER">
              <img src="./images/ziliwang.jpg" height="250" align="left">
            </td>

            <td valign="CENTER" width="2%">
            </td>

            <td valign="CENTER" halign="LEFT">
              <font size="+0">
                <b><font size="+2">Zili Wang&nbsp;</font></b>
                <p style="margin-left:0px;">
                  <img src="./images/name.png" height="60">
                </p>
                <p style="margin-left:0px;">
                  <!-- <b>Algorithm Expert</b> -->
                </p>
                <p style="margin-left:0px;">
                  <!-- <a href="http://www.nextcenter.org/", target="_blank">NExT++</a><br/> -->
                  <a href="https://www.infly.cn/" target="_blank">INF Technology</a><br/>
                  <!-- <a href="https://www.polyu.edu.hk/", target="_blank">Hong Kong Polytechnic University</a><br/> -->
                </p>
                <p style="margin-left:0px;">
                  Shang Hai, China<br>
                </p>
                <p style="margin-left:0px;">
                  Email: ziliwang.do@gmail.com<br>
                  &bull; <a href="">CV</a> &bull; <a href="https://scholar.google.com/citations?hl=zh-CN&user=E9zWgmwAAAAJ">Google Scholar</a> &bull; <a href="https://github.com/commencement">GitHub</a> <br>
                </p>
              </font>
              <p><font size="+0">
                </font>
              </p>
            </td>
          </tr>
        </tbody>
      </table>

      <div style="margin-top:20px;">
        Zili Wang is currently an Algorithm Expert at <a href="https://www.infly.cn/">INF Technology</a>, focusing on large language model pretraining. Previously, he worked as an Algorithm Engineer at Xiaohongshu Inc. (March 2022 - September 2023) with <a href="https://wangshusen.github.io/">Prof. Shusen Wang</a>. He was a Research Intern at Microsoft Asia (October 2020 - February 2021) under Xueting Han, and a Research Assistant at Hong Kong Polytechnic University since February 2020 with <a href="https://www4.comp.polyu.edu.hk/~cswjli/">Prof. Wenjie Li</a>. He also interned at Meituan-Dianping's AI Lab (June 2019 - November 2019) with <a href="https://sites.google.com/site/bitwjg/">Dr. Jingang Wang</a> and <a href="https://zhfzhmsra.github.io/">Dr. Fuzheng Zhang</a>, and at Peking University (October 2018 - May 2019) with <a href="https://xusun26.github.io/">Prof. Xu Sun</a>.
      </div>

      <h2 style="CLEAR: both;">Recent Projects</h2>

      <div class="model-info">
        <p><strong>INF-34B: INF’s Open-Source Large Language Models</strong></p>
        <p>INF-34B has 34 billion parameters with a context window length of 32K, and is trained on about 3.5T well-processed tokens from English and Chinese bilingual corpus. Compared with open source models of comparable size, INF-34B not only provides competitive performance in the OpenCompass evaluation, but also has impressive potential in both finance and healthcare domains. Besides, the quantized INF-34B runs on graphics cards of 24GB VRAM with negligible accuracy loss, which facilitates commercial applications, especially low-resource scenarios.</p>
        <p>Links:
          <a href="https://github.com/infly-ai/INF-LLM" target="_blank">
            <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" style="width: 16px; height: 16px; vertical-align: middle;"> GitHub
          </a> |
          <a href="https://huggingface.co/infly/INF-34B-Base" target="_blank">
            <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="HuggingFace" style="width: 16px; height: 16px; vertical-align: middle;"> HuggingFace
          </a> |
          <a href="https://s.infly.cn/f/img/pdf/inf_34b_tech_report.pdf" target="_blank">
            <img src="https://upload.wikimedia.org/wikipedia/commons/8/87/PDF_file_icon.svg" alt="Tech Report" style="width: 16px; height: 16px; vertical-align: middle;"> Tech Report
          </a>
        </p>
      </div>

      <h2 style="CLEAR: both">Large Language Model Pretraining Related Publications </h2>
      </br>

      <table>
        <tbody>
          <tr>
            <td class="left"><a href="https://s.infly.cn/f/img/pdf/inf_34b_tech_report.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">INF’s Open-Source Large Language Models</span> 
              <br>Jiaran Hao, <b>Zili Wang</b>, LiuYihan Song, Ansheng You, Zhipeng Zhou, Xiaoyu Tan, Dakuan Lu, Xiaoming Shi, Chao Qu, Haozhe Wang, Yinghui Xu, Wei Chu, Yuan Qi
              <br>&nbsp;&nbsp;&bull; <a href="https://s.infly.cn/f/img/pdf/inf_34b_tech_report.pdf" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/infly-ai/INF-LLM/" target="_blank">Codes</a> &nbsp;&nbsp;
              &bull; <a href="https://huggingface.co/infly/INF-34B-Base/" target="_blank">Huggingface</a> &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2402.12656" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts</span> 
              <br>Haoze Wu, Zihan Qiu, <b>Zili Wang</b>, Hang Zhao, Jie Fu
              <br>ACL 2024
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/pdf/2402.12656" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/Bumble666/Hyper_MoE" target="_blank">Codes</a> &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2305.14994.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">RefGPT: Reference-> Truthful & Customized Dialogues Generation by GPTs and for GPTs</span> 
              <br>Dongjie Yang, Ruifeng Yuan, YuanTao Fan, YiFei Yang, <b>Zili Wang</b>, Shushen Wang, Hai Zhao
              <br>EMNLP 2023
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2305.14994" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/mutonix/RefGPT" target="_blank">Codes</a> &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2306.05783.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation</span> 
              <br>Zhouhong Gu, Xiaoxuan Zhu, Haoning Ye, Lin Zhang, Jianchen Wang, Sihang Jiang, Zhuozhi Xiong, Zihan Li, Qianyu He, Rui Xu, Wenhao Huang, <b>Zili Wang</b>, Shusen Wang, Weiguo Zheng, Hongwei Feng, Yanghua Xiao
              <br>AAAI 2024
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2306.05783" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/MikeGu721/XiezhiBenchmark" target="_blank">Codes</a> &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/abs/2406.12375" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">GW-MoE: Resolving Uncertainty in MoE Router with Global Workspace Theory</span> 
              <br>Haoze Wu, Zihan Qiu, <b>Zili Wang</b>, Hang Zhao, Jie Fu
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2406.12375" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/WaitHZ/GW-MoE" target="_blank">Codes</a> &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2406.18219" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">A Closer Look into Mixture-of-Experts in Large Language Models</span> 
              <br>Ka Man Lo, Zeyu Huang, Zihan Qiu, <b>Zili Wang</b>, Jie Fu
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2406.18219" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/kamanphoebe/Look-into-MoEs" target="_blank">Codes</a> &nbsp;&nbsp;
              &bull; Slides &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2312.17257" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">Evolving Large Language Model Assistant with Long-Term Conditional Memory</span> 
              <br>Ruifeng Yuan, Shichao Sun, <b>Zili Wang</b>, Ziqiang Cao, Wenjie Li
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/pdf/2312.17257" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://arxiv.org/pdf/2312.17257" target="_blank">Codes</a> &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2405.19327" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">Map-neo: Highly capable and transparent bilingual large language model series</span> 
              <br>Ge Zhang, Scott Qu, Jiaheng Liu, Chenchen Zhang, Chenghua Lin, Chou Leuang Yu, Danny Pan, Esther Cheng, Jie Liu, Qunshu Lin, Raven Yuan, Tuney Zheng, Wei Pang, Xinrun Du, Yiming Liang, Yinghao Ma, Yizhi Li, Ziyang Ma, Bill Lin, Emmanouil Benetos, Huan Yang, Junting Zhou, Kaijing Ma, Minghao Liu, Morry Niu, Noah Wang, Quehry Que, Ruibo Liu, Sine Liu, Shawn Guo, Soren Gao, Wangchunshu Zhou, Xinyue Zhang, Yizhi Zhou, Yubo Wang, Yuelin Bai, Yuhan Zhang, Yuxiang Zhang, <b>Zenith Wang</b>, Zhenzhu Yang, Zijian Zhao, Jiajun Zhang, Wanli Ouyang, Wenhao Huang, Wenhu Chen
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2405.19327" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/multimodal-art-projection/MAP-NEO" target="_blank">Codes</a> &nbsp;&nbsp;
              &bull; Slides &nbsp;&nbsp;
            </td>
          </tr>
        </tbody>
      </table>

      <h2 style="CLEAR: both">Multimodal model Related Publications </h2>
      <table>
        <tbody>
          </br>
          <tr>
            <td class="left"><a href="https://arxiv.org/abs/2402.19155" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">Beyond Language Models: Byte Models are Digital World Simulators</span> 
              <br>Shangda Wu, Xu Tan, <b>Zili Wang</b>, Rui Wang, Xiaobing Li, Maosong Sun
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2402.19155" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/sanderwood/bgpt" target="_blank">Codes</a> &nbsp;&nbsp;
              &bull; Slides &nbsp;&nbsp;
            </td>
          </tr>

          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2406.07588" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">AIM: Let Any Multi-modal Large Language Models Embrace Efficient In-Context Learning</span> 
              <br>Jun Gao, Qian Qiao, Ziqiang Cao, <b>Zili Wang</b>, Wenjie Li
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2406.07588" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://commencement.github.io/" target="_blank">Codes</a> &nbsp;&nbsp;
              &bull; Slides &nbsp;&nbsp;
            </td>
          </tr>
        </tbody>
      </table>

      <h2 style="CLEAR: both">LLM-based Agent Related  Publications </h2>
      <table>
        <tbody>
          <tr>
            <td class="left"><a href="https://arxiv.org/pdf/2308.00352.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
            <td><span class="title">Metagpt: Meta programming for multi-agent collaborative framework</span> 
              <br>Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, <b>Zili Wang</b>, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu
              <br>ICLR 2024
              <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2308.00352" target="_blank">arXiv</a> &nbsp;&nbsp;
              &bull; <a href="https://github.com/geekan/MetaGPT" target="_blank">Codes</a> &nbsp;&nbsp;
            </td>
          </tr>
        </tbody>
      </table>

      <h2 style="CLEAR: both">Text Summarization Related  Publications </h2>
      <table>
        <tbody>
          <tr>
            <tr>
              <td class="left"><a href="https://arxiv.org/pdf/2305.14994.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
              <td><span class="title">QuerySum: A Multi-Document Query-Focused Summarization Dataset</span> 
                <br>Yushan Liu, <b>Zili Wang</b>, Ruifeng Yuan
                <br>AAAI 2024
                <br>&nbsp;&nbsp;&bull; <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29836" target="_blank">arXiv</a> &nbsp;&nbsp;
                &bull; <a href="" target="_blank">Codes</a> &nbsp;&nbsp;
              </td>
            </tr>

            <tr>
              <td class="left"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/26631" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
              <td><span class="title">Preserve Context Information through Interpretability for Extract-Generate Long-Input Summarization Framework</span> 
                <br>Ruifeng Yuan,  <b>Zili Wang</b>,  Ziqiang Cao, Wenjie Li
                <br>AAAI 2023
                <br>&nbsp;&nbsp;&bull; <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26631" target="_blank">arXiv</a> &nbsp;&nbsp;
                &bull; <a href="https://commencement.github.io/" target="_blank">Codes</a> &nbsp;&nbsp;
              </td>
            </tr>

            <tr>
              <td class="left"><a href="https://arxiv.org/pdf/2211.16164.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
              <td><span class="title">Few-shot Query-Focused Summarization with Prefix-Merging</span> 
                <br>Ruifeng Yuan,  <b>Zili Wang</b>,  Wenjie Li
                <br>EMNLP 2022
                <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2211.16164" target="_blank">arXiv</a> &nbsp;&nbsp;
                &bull; <a href="https://github.com/RuifengYuan/Prefix_Merging" target="_blank">Codes</a> &nbsp;&nbsp;
              </td>
            </tr>

            <tr>
              <td class="left"><a href="https://aclanthology.org/2021.emnlp-main.334.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
              <td><span class="title">Event Graph based Sentence Fusion</span> 
                <br>Ruifeng Yuan*,  <b>Zili Wang</b>*<b>(Equal Contribution)</b>,  Wenjie Li
                <br>EMNLP 2021 
                <br>&nbsp;&nbsp;&bull; <a href="https://aclanthology.org/2021.emnlp-main.334.pdf" target="_blank">arXiv</a> &nbsp;&nbsp;
                &bull; <a href="https://github.com/RuifengYuan/Sentence-Fusion-with-event-graph" target="_blank">Codes</a> &nbsp;&nbsp;
              </td>
            </tr>

            <tr>
              <td class="left"><a href="files/Fact-level Extractive Summarization withHierarchical Graph Mask on BERT.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
              <td><span class="title">Fact level Extractive Summarization with Hierarchical Graph Mask on BERT</span> 
                <br>Ruifeng Yuan,  <b>Zili Wang</b>,  Wenjie Li
                <br>COLING 2020 
                <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2011.09739" target="_blank">arXiv</a> &nbsp;&nbsp;
                &bull; <a href="https://github.com/RuifengYuan/FactExsum-coling2020" target="_blank">Codes</a> &nbsp;&nbsp;
              </td>
            </tr>

            <tr>
              <td class="left"><a href="files/CIKM_2020_Tip_Generation.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
              <td><span class="title">Query-aware Tip Generation for Vertical Search</span> 
                <br>Yang Yang*, Junmei Hao*, Canjia Li*, <b>Zili Wang</b>*<b>(Equal Contribution)</b>, Jingang Wang, Fuzheng Zhang, Rao Fu, Peixu Hou, Gong Zhang, Zhongyuan Wang
                <br>CIKM 2020 
                <br>&nbsp;&nbsp;&bull; <a href="https://arxiv.org/abs/2010.09254" target="_blank">arXiv</a> &nbsp;&nbsp;
                &bull; <a href="https://commencement.github.io/" target="_blank">Codes</a> &nbsp;&nbsp;
                &bull; <a href="files/cikm-tip-generation.pdf" target="_blank">Slides</a> &nbsp;&nbsp;
              </td>
            </tr>
          </tr>
        </tbody>
      </table>

      <b> Look for the full publication list? Please see <a href="" target="_blank">my CV</a> or visit <a href="https://scholar.google.com/citations?hl=zh-CN&user=E9zWgmwAAAAJ" target="_blank">Google Scholar</a>.</b></br></br>

      <h2 style="CLEAR: both;">Professional Services</h2>
      <br>
      Program Committee Member of <span class="title">ACM CIKM (2023) </span> <br>
      Program Committee Member of <span class="title">ACM CIKM (2022) </span> <br>
      Program Committee Member of <span class="title">ACM CIKM (2021) </span> <br>
      </td></tr></tbody></table>

      </br>

      <h2 style="CLEAR: both;"></h2>
      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=P5t3EabrzZY8aFh3ZhuRPAXXUh7jCpV3TVHKUlqbMjA&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
    </div>
  </div>
</body>
</html>
